<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>AI专业问题 - Tlo_oh</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="Tlo_oh"><meta name="msapplication-TileImage" content="/img/mypicture.jpg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Tlo_oh"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="机器学习"><meta property="og:type" content="blog"><meta property="og:title" content="AI专业问题"><meta property="og:url" content="https://www.ferrystars.xyz/2022/03/15/AI%E4%B8%93%E4%B8%9A/"><meta property="og:site_name" content="Tlo_oh"><meta property="og:description" content="机器学习"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://www.ferrystars.xyz/img/mypicture.jpg"><meta property="article:published_time" content="2022-03-15T03:30:06.000Z"><meta property="article:modified_time" content="2022-03-18T03:30:14.000Z"><meta property="article:author" content="Tlo_oh"><meta property="article:tag" content="Deep Learning"><meta property="article:tag" content="Machine Learning"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/img/mypicture.jpg"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://www.ferrystars.xyz/2022/03/15/AI%E4%B8%93%E4%B8%9A/"},"headline":"Tlo_oh","image":["https://gitee.com/SysYolo/cloudimage/raw/master/img/ubuntu/20220321132955.png"],"datePublished":"2022-03-15T03:30:06.000Z","dateModified":"2022-03-18T03:30:14.000Z","author":{"@type":"Person","name":"Tlo_oh"},"description":"机器学习"}</script><link rel="canonical" href="https://www.ferrystars.xyz/2022/03/15/AI%E4%B8%93%E4%B8%9A/"><link rel="icon" href="/img/mypicture.jpg"><meta name="referrer" content="no-referrer-when-downgrade"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/font-awesome/5.12.0/css/all.min.css"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/highlight.js/9.12.0/styles/atom-one-light.min.css"><link rel="stylesheet" href="https://fonts.loli.net/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/font-awesome/5.12.0/css/all.min.css"><link rel="stylesheet" href="https://fonts.loli.net/css?family=Ubuntu:400,600|Source+Code+Pro|Monda:300,300italic,400,400italic,700,700italic|Roboto Slab:300,300italic,400,400italic,700,700italic|Microsoft YaHei:300,300italic,400,400italic,700,700italic|PT Mono:300,300italic,400,400italic,700,700italic&amp;amp;subset=latin,latin-ext|Inconsolata|Itim|Lobster.css"><script src="https://cdnjs.loli.net/ajax/libs/jquery/3.3.1/jquery.min.js"></script><script src="/js/globalUtils.js"></script><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" defer></script><!--!--><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/lightgallery/1.6.8/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/justifiedGallery/3.7.0/css/justifiedGallery.min.css"><!--!--><!--!--><script src="https://cdnjs.loli.net/ajax/libs/pace/1.0.2/pace.min.js"></script><script async="" referrerpolicy="no-referrer" src="//cdn.jsdelivr.net/npm/leancloud-storage@3/dist/av-min.js"></script><script src="//unpkg.com/valine/dist/Valine.min.js"></script><script src="/js/md5.min.js"></script><meta name="generator" content="Hexo 5.4.1"></head><body class="is-3-column has-navbar-fixed-top"><nav class="navbar navbar-main is-fixed-top"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.png" alt="Tlo_oh" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">主页</a><a class="navbar-item" href="/archives">归档</a><a class="navbar-item" href="/categories">分类</a><a class="navbar-item" href="/tags">标签</a><a class="navbar-item" href="/about">关于</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Join Gitter" href="https://gitter.im/hexo-theme-amazing/community"><i class="fab fa-gitter"></i></a><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/removeif/hexo-theme-amazing"><i class="fab fa-github"></i></a><a class="navbar-item is-hidden-tablet catalogue" title="目录" href="javascript:;"><i class="fas fa-list-ul"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a><a class="navbar-item" id="night-nav" title="Night Mode" href="javascript:;"><i class="fas fa-moon" id="night-icon"></i></a></div></div></div></nav><script type="text/javascript" src="/js/theme-setting.js"></script><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-9-widescreen"><!--!--><div class="card"><div class="card-image"><span class="image is-7by3"><img class="fill" src="https://gitee.com/SysYolo/cloudimage/raw/master/img/ubuntu/20220321132955.png" alt="AI专业问题"></span></div><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><i class="far fa-calendar-plus"> </i>2022-03-15  <span class="level-item"> Tlo_oh </span><a class="commentCountImg" href="/2022/03/15/AI%E4%B8%93%E4%B8%9A/#comment-container"><span class="display-none-class">/2022/03/15/AI专业/</span><i class="far fa-comment-dots"></i> <span class="commentCount" id="f7865acaaed11a3d904f7e2705af1c90">99+</span>  </a><span class="level-item"><i class="far fa-clock"> </i>1 小时  <i class="fas fa-pencil-alt"> </i>7.0 k</span><span class="level-item" id="busuanzi_container_page_pv"><span id="busuanzi_value_page_pv">0</span>次访问</span></div></div><h1 class="title is-3 is-size-4-mobile">AI专业问题</h1><div class="content"><blockquote>
<p>机器学习</p>
</blockquote>
<span id="more"></span>





<h2 id="1、损失函数"><a href="#1、损失函数" class="headerlink" title="1、损失函数"></a>1、损失函数</h2><h3 id="1）定义"><a href="#1）定义" class="headerlink" title="1）定义"></a>1）定义</h3><p>在深度学习中, 损失函数是用来衡量模型参数的质量的函数, 衡量的方式是比较模型输出和真实输出的差异；</p>
<p>四种叫法：</p>
<p><img src="https://cdn.jsdelivr.net/gh/Tlooh/blog-imgs/blog202203281349380.png"></p>
<h3 id="2）应用地方"><a href="#2）应用地方" class="headerlink" title="2）应用地方"></a>2）应用地方</h3><p>分类任务中使用最多的是<strong>交叉熵损失函数</strong>；</p>
<p>多分类任务通常使用<code>softmax</code>将<code>logits</code>转换为概率的形式，所以多分类的<strong>交叉熵损失</strong>也叫做<code>softmax损失</code></p>
<h2 id="2、梯度下降"><a href="#2、梯度下降" class="headerlink" title="2、梯度下降"></a>2、梯度下降</h2><p>用于优化深度学习</p>
<h3 id="1）定义-1"><a href="#1）定义-1" class="headerlink" title="1）定义"></a>1）定义</h3><p>梯度下降简单来说就是一种寻找损失函数最小化的方法。</p>
<p>补：梯度的方向是函数增长<strong>速度最快</strong>的方向，那么梯度的负方向就是函数<strong>减少最快</strong>的方向；</p>
<p><strong>梯度：</strong>在训练过程中损失函数对权重的偏导数就是损失函数在该位置点的梯度。</p>
<p>沿着负梯度方向移动，就可以到达损失函数底部，从而使损失函数最小化。这种利用损失函数的梯度迭代地寻找局部最小值的过程就是梯度下降的过程。</p>
<p><img src="https://gitee.com/SysYolo/cloudimage/raw/master/img/ubuntu/20220315204054.png" alt="image-20220315204053554"></p>
<h3 id="2）算法中遇到的问题"><a href="#2）算法中遇到的问题" class="headerlink" title="2）算法中遇到的问题"></a>2）算法中遇到的问题</h3><p><img src="https://gitee.com/SysYolo/cloudimage/raw/master/img/ubuntu/20220315204054.png" alt="image-20220315211359412"></p>
<h4 id="鞍点"><a href="#鞍点" class="headerlink" title="鞍点"></a>鞍点</h4><ul>
<li>动量算法、动量梯度下降算法</li>
</ul>
<h4 id="局部极小值"><a href="#局部极小值" class="headerlink" title="局部极小值"></a>局部极小值</h4><ul>
<li>RMSProp（Root Mean Square Prop）算法将这些梯度按元素平方做指数加权移动平均</li>
</ul>
<h2 id="3、前、反向传播算法"><a href="#3、前、反向传播算法" class="headerlink" title="3、前、反向传播算法"></a>3、前、反向传播算法</h2><h3 id="1-反向传播算法（BP算法）"><a href="#1-反向传播算法（BP算法）" class="headerlink" title="1)反向传播算法（BP算法）"></a>1)反向传播算法（BP算法）</h3><h4 id="用途："><a href="#用途：" class="headerlink" title="用途："></a>用途：</h4><p>​    该方法与<strong>梯度下降算法</strong>相结合，对网络中所有权重计算损失函数的梯度；</p>
<p>然后利用梯度值<strong>更新权值</strong>以<strong>最小化损失函数；</strong></p>
<h4 id="定义："><a href="#定义：" class="headerlink" title="定义："></a>定义：</h4><p>在网络的训练过程中经过前向传播后得到的最终结果跟训练样本的真实值总是存在一定误差，这个误差便是损失函数。</p>
<p>想要减小这个误差，就根据损失函数，<strong>从后往前，</strong>依次求<strong>各个参数的偏导</strong>，这就是反向传播（Back Propagation）。</p>
<h4 id="计算方法："><a href="#计算方法：" class="headerlink" title="计算方法："></a>计算方法：</h4><p>反向传播算法是利用<strong>链式法则</strong>进行梯度求解及权重更新的</p>
<p>对于复杂的函数，我们将其拆分为一系列的加减乘除等初等函数，通过链式法则完成复合函数的求导。</p>
<h3 id="2-前向传播算法"><a href="#2-前向传播算法" class="headerlink" title="2)前向传播算法"></a>2)前向传播算法</h3><p>定义：指的是数据输入到神经网络中、<strong>逐层向前传输</strong>，一直运算到输出层为止</p>
<h2 id="4、正则化"><a href="#4、正则化" class="headerlink" title="4、正则化"></a>4、正则化</h2><h3 id="1）解释"><a href="#1）解释" class="headerlink" title="1）解释"></a>1）解释</h3><p>设计机器学习算法时，不仅要考虑训练集上的误差，而且希望模型的在新样本上的泛化能力强；</p>
<p>许多机器学习算法都需要相关策略去减小测试误差，这个策略统称为正则化；</p>
<p>因为神经网络强大的表示能力经常遇到过拟合，所以需要不同形式的正则化策略。</p>
<p>通过对算法的修改减少泛华误差；</p>
<h3 id="2）常见正则化的策略"><a href="#2）常见正则化的策略" class="headerlink" title="2）常见正则化的策略"></a>2）常见正则化的策略</h3><ul>
<li><strong>L1 与 L2 正则化</strong></li>
</ul>
<p>在损失函数中增加一个正则项，由于这个正则化项，权重矩阵的值减小；</p>
<p>因为它假定具有更小权重矩阵的神经网络导致更简单的模型；</p>
<p>因此，它会在一定程度上减少过拟合。（L1和L2的不同就在于这个正则化项）</p>
<ul>
<li><strong>参数范数惩罚</strong></li>
<li><strong>提前停止</strong></li>
</ul>
<p>将一部分训练集作为验证集，当验证集的性能越来越差时或者不再提升时，则立即停止对模型的训练。</p>
<ul>
<li><strong>Dropout正则化</strong></li>
</ul>
<p>深度学习领域常见的正则化技术；</p>
<p>原理：在每个迭代过程中，随机选择某些节点删除前向和后向连接，因此每个迭代会有不同的节点导致不同的输出，这类似于集成方法，<strong>集成模型</strong>（发散思考：集成模型？）一般优于单一模型。</p>
<p><img src="https://gitee.com/SysYolo/cloudimage/raw/master/img/ubuntu/20220315214738.png" alt="image-20220315214737590"></p>
<h2 id="5、卷积神经网络"><a href="#5、卷积神经网络" class="headerlink" title="5、卷积神经网络"></a>5、卷积神经网络</h2><h3 id="1）解释-1"><a href="#1）解释-1" class="headerlink" title="1）解释"></a><strong>1）解释</strong></h3><p>CNN神经网络受人类视觉神经系统的启发，就比如当我们看到一个人脸时，</p>
<p>首先需要接收原始信号的输入（瞳孔摄入像素）；</p>
<p>接着做初步处理，大脑皮层分析确定边缘和方向；</p>
<p>然后抽象，判断眼前物体的形状，是圆形的；</p>
<p>接着进一步抽象，判断为人脸；</p>
<p>构成：</p>
<ul>
<li>卷积层：负责提取图像局部特征</li>
<li>池化层：大幅降低参数量级（降维）</li>
<li>全连接层：类似人工神经网络的部分，输出想要的结果</li>
</ul>
<h3 id="2）卷积层"><a href="#2）卷积层" class="headerlink" title="2）卷积层"></a><strong>2）卷积层</strong></h3><p>提取输入图像的就不特征，卷积核可以提取图像中的边缘信息</p>
<p><img src="https://gitee.com/SysYolo/cloudimage/raw/master/img/ubuntu/20220316222846.png"></p>
<p>多通道卷积：实际中的图像都是由多个通道组成的，这时候我们的卷积核需要拥有相同的channel数，每个卷积核channel与输入层对应的channel进行卷积，将最后的结果按位相加得到最终的Feature。</p>
<h3 id="3）池化层"><a href="#3）池化层" class="headerlink" title="3）池化层"></a><strong>3）池化层</strong></h3><ul>
<li>降低了后续网络层的输入维度，缩减模型大小，提高计算速度</li>
<li>提高了Feature Map 的鲁棒性，防止过拟合，</li>
</ul>
<p>主要是对卷积层学习到的特征图进行下采样（subsampling）处理，两种方法：</p>
<ul>
<li>最大池化：取窗口内的最大值作为输出</li>
<li>平均池化：取窗口内的所有值的均值进行输出</li>
</ul>
<h3 id="4）全连接层"><a href="#4）全连接层" class="headerlink" title="4）全连接层"></a><strong>4）全连接层</strong></h3><p>位于CNN的末端，经过卷积层的特征提取与池化层的降维后：</p>
<p>将特征图转换为一维向量送入到全连接层中进行分类或回归的操作；</p>
<h3 id="5）常见的架构模型"><a href="#5）常见的架构模型" class="headerlink" title="5）常见的架构模型"></a><strong>5）常见的架构模型</strong></h3><h4 id="LeNet-5"><a href="#LeNet-5" class="headerlink" title="LeNet-5"></a><strong>LeNet-5</strong></h4><p><img src="https://gitee.com/SysYolo/cloudimage/raw/master/img/ubuntu/20220316223917.png"></p>
<h4 id="AlexNet"><a href="#AlexNet" class="headerlink" title="AlexNet"></a><strong>AlexNet</strong></h4><p>与LeNet-5相似，但也有显著区别</p>
<ul>
<li>AlexNet包含8层变换，有5层卷积和2层全连接隐藏层，以及1个全连接输出层</li>
<li>AlexNet第一层中的卷积核形状是11×1111×11。第二层中的卷积核形状减小到5×55×5，之后全采用3×33×3。所有的池化层窗口大小为3×33×3、步幅为2的最大池化。（卷积核形状的改变和选择）</li>
<li>AlexNet将sigmoid激活函数改成了ReLU激活函数，使计算更简单，网络更容易训练；</li>
<li>AlexNet通过<code>dropOut</code>来控制全连接层的模型复杂度。</li>
<li>AlexNet引入了大量的图像增强，如翻转、裁剪和颜色变化，从而进一步扩大数据集来缓解过拟合。</li>
</ul>
<h4 id="VGG"><a href="#VGG" class="headerlink" title="VGG"></a><strong>VGG</strong></h4><p>VGG可以看成是加深版的AlexNet，整个网络由卷积层和全连接层叠加而成；</p>
<p>和AlexNet不同的是，VGG中使用的都是小尺寸的卷积核(3×3)，</p>
<h2 id="6、图像增强"><a href="#6、图像增强" class="headerlink" title="6、图像增强"></a>6、图像增强</h2><h3 id="1）作用"><a href="#1）作用" class="headerlink" title="1）作用"></a><strong>1）作用</strong></h3><p>大规模数据集是深度卷积神经网络的前提；</p>
<p>例如，我们可以通过对图像的裁剪、平移、使得感兴趣的物体出现在不同的位置，减轻模型对物体位置的依赖性；</p>
<p>调整亮度、色彩等因素降低模型对色彩的敏感度。</p>
<p>通过图像增强，我们对训练图像做一系列随机变换，从而降低模型对某些属性的依赖，从而<strong>提高模型的泛化能力</strong></p>
<h3 id="2）常用方法"><a href="#2）常用方法" class="headerlink" title="2）常用方法"></a><strong>2）常用方法</strong></h3><p>几何变换+颜色变换</p>
<h2 id="7、微调"><a href="#7、微调" class="headerlink" title="7、微调"></a>7、微调</h2><h3 id="1）解释-2"><a href="#1）解释-2" class="headerlink" title="1）解释"></a><strong>1）解释</strong></h3><p>它是一个迁移学习。假如我们需要做一个椅子的分类任务，除了找好相关的数据集去训练以外，还有一种方法：</p>
<ul>
<li>将源数据集学到的知识迁移到目标数据集上</li>
<li>该数据集训练的模型可以抽取较通用的图像特征，从而能够帮助识别边缘、纹理、形状和物体等</li>
<li>这些特征同样适用于识别椅子</li>
</ul>
<p>做法就是，新建一个模型，它复制了源模型上除了输出层以外的其它层和参数，然后再在我们的目标数据集上，从头训练目标模型，重新训练输出层，而其余的参数都是基于模型的参数微调得到的。</p>
<p>当目标数据集远小于源数据集时，微调有助于提升模型的泛化能力。</p>
<h2 id="8、目标检测"><a href="#8、目标检测" class="headerlink" title="8、目标检测"></a>8、目标检测</h2><p>常用的开源数据集：<strong>PASCAL VOC数据集</strong> </p>
<h3 id="1）常用的评价指标"><a href="#1）常用的评价指标" class="headerlink" title="1）常用的评价指标"></a>1）常用的评价指标</h3><ul>
<li><strong>IoU（intersection over union，交并比）</strong></li>
</ul>
<p>目标检测算法中用来评价2个矩形框之间相似度的指标</p>
<ul>
<li><strong>mAP（<em>Mean Average Precision</em>）</strong></li>
</ul>
<p>mAP是多个分类任务的AP的平均值，而AP（average precision）是PR曲线下的面积，所以在介绍mAP之前我们要先得到PR曲线。</p>
<h3 id="2）NMS（非极大值抑制）"><a href="#2）NMS（非极大值抑制）" class="headerlink" title="2）NMS（非极大值抑制）"></a>2）NMS（非极大值抑制）</h3><p>顾名思义就是抑制不是极大值的元素。</p>
<p>如在目标检测中，滑动窗口经提取特征，经分类器分类识别后，每个窗口都会得到一个分数。</p>
<p>但是滑动窗口会导致很多窗口与其他窗口存在包含或者大部分交叉的情况。这时就需要用到NMS来选取那些邻域里分数最高（是行人的概率最大），并且抑制那些分数低的窗口。</p>
<p>在目标检测中，NMS的目的就是要去除冗余的检测框,保留最好的一个；</p>
<h3 id="3）目标检测方法分类"><a href="#3）目标检测方法分类" class="headerlink" title="3）目标检测方法分类"></a>3）目标检测方法分类</h3><ul>
<li><strong>two-stage的算法</strong></li>
</ul>
<p>先由算法生成一系列作为样本的候选框，再通过卷积神经网络进行样本分类。</p>
<p>主要通过一个卷积神经网络来完成目标检测过程，其提取的是CNN卷积特征；在训练过程中，主要训练<strong>候选区域的筛选</strong>和<strong>目标检测</strong>两部分。</p>
<p><strong>特点</strong>： 网络的准确度高、速度相对较慢。</p>
<p>two-stages算法的代表是RCNN系列：R-CNN到Faster R-CNN网络</p>
<ul>
<li><strong>One-stage的算法</strong></li>
</ul>
<p>直接通过主干网络给出目标的类别和位置信息，没有使用候选区域的筛选网路，</p>
<p>特点：速度快，但是精度降低了很多。</p>
<p>one-stage算法的代表是： YOLO系列：YOLOv1、YOLOv2、YOLOv3、 SSD等</p>
<h2 id="9、R-CNN"><a href="#9、R-CNN" class="headerlink" title="9、R-CNN"></a><strong>9、R-CNN</strong></h2><h3 id="1）解释-3"><a href="#1）解释-3" class="headerlink" title="1）解释"></a><strong>1）解释</strong></h3><p>在早期的Overfeat模型中，它使用固定宽、高的矩形框，在图像上滑动，并将扫描结果送入到神经网络中进行分类和回归；</p>
<p>但这样类似暴力穷举，需要非常大的计算力；</p>
<p>而R-CNN在这一点上做了改进，它不再使用暴力穷举的方法，而是使用候选区域的方法创建目标检测的区域来完成任务；</p>
<p>步骤：</p>
<ol>
<li><strong>候选区域生成</strong>：使用选择性搜索（Selective Search）的方法找出图片中可能存在目标的侯选区域</li>
<li><strong>CNN网络提取特征</strong>：选取预训练卷积神经网络（AlexNet或VGG）用于进行特征提取。</li>
<li><strong>目标分类</strong>：训练支持向量机（SVM）来辨别目标物体和背景，对每个类别，都要训练一个二元SVM。</li>
<li><strong>目标定位</strong>：训练一个线性回归模型，为每个辨识到的物体生成更精确的边界框。</li>
</ol>
<h3 id="2）算法总结"><a href="#2）算法总结" class="headerlink" title="2）算法总结"></a><strong>2）算法总结</strong></h3><ul>
<li>训练阶段多、非常耗时</li>
<li>预测速度慢</li>
<li>占用磁盘空间大：有些5000张图像产生几百G的特征文件</li>
<li>数据的形状变化：候选区域要经过缩放来固定大小、无法保证目标的不变形</li>
</ul>
<h3 id="3）Fast-R-CNN"><a href="#3）Fast-R-CNN" class="headerlink" title="3）Fast R-CNN"></a><strong>3）Fast R-CNN</strong></h3><p>改进地方：</p>
<ul>
<li><strong>减少了重复计算、提高了速度</strong></li>
</ul>
<p>RCNN将分别将候选区域送入到神经网络中进行特征提取，由于候选区域有大量的重叠，会导致许多重复的计算；</p>
<p>而在Fast RCNN中，它将整张图输入到CNN中提取特征，然后再讲候选区域映射到特征图上，这样就避免了对图像区域进行重复处理；</p>
<ul>
<li><strong>不需要额外的空间</strong></li>
</ul>
<p>RCNN中需要将提取到的特征保存下来，用于为每个类训练单独的SVM分类器和边框回归器；</p>
<p>FastRCNN中，将类别判断和回归统一使用CNN实现，不需要额外的空间存储特征；</p>
<ul>
<li><strong>不直接对候选区域进行缩放</strong></li>
</ul>
<p>RCNN中需要对候选区域进行缩放送入CNN中进行特征提取，在Fast-RCNN中使用ROIpooling的方法进行尺寸的调整。</p>
<p>步骤是：</p>
<p>1、<strong>候选区域生成</strong>：使用选择性搜索（Selective Search）的方法找出图片中可能存在目标的侯选区域，只需要候选区域的位置信息</p>
<p>2、<strong>CNN网络特征提取</strong>：将整张图像输入到CNN网络中，得到整副图的特征图，并将上一步获取的候选区域位置从原图映射到该特征图上</p>
<p>3、<strong>ROIPooling</strong>: 对于每个特征图上候选框，RoI pooling层从特征图中提取固定长度的特征向量每个特征向量被送入一系列全连接（fc）层中。</p>
<p>4、<strong>目标检测</strong>：分两部分完成，一个输出各类别加上1个背景类别的Softmax概率估计，另一个为各类别的每一个类别输出四个实数值，来确定目标的位置信息。</p>
<h3 id="4）Faster-R-CNN"><a href="#4）Faster-R-CNN" class="headerlink" title="4）Faster R-CNN"></a><strong>4）Faster R-CNN</strong></h3><p>Faster R-CNN的流程与Fast R-CNN的区别不是很大;</p>
<p>重要的改进: 使用<strong>RPN网络</strong>来替代<strong>选择性搜</strong>索获取候选区域，</p>
<h2 id="10、yolo系列"><a href="#10、yolo系列" class="headerlink" title="10、yolo系列"></a>10、yolo系列</h2><h3 id="batch-normalization"><a href="#batch-normalization" class="headerlink" title="batch normalization"></a><strong>batch normalization</strong></h3><p>批标准化有助于解决反向传播过程中的梯度消失和梯度爆炸问题，降低对一些超参数的敏感性，并且每个batch分别进行归一化的时候，起到了一定的正则化效果，从而能够获得更好的收敛速度和收敛效果。</p>
<h2 id="11、支持向量机"><a href="#11、支持向量机" class="headerlink" title="11、支持向量机"></a>11、支持向量机</h2><p>二分类的本质就是在数据的特征空间内，寻找间距最大的超平面，将数据划分为两类，以实现区分。</p>
<p>SVM还包括核技巧，这让它成为实质上的非线性分类器；</p>
<p>SVM的学习策略就是间隔最大化，学习算法就是求解凸二次规划的最优化算法；</p>
<h3 id="1）何为线性可分"><a href="#1）何为线性可分" class="headerlink" title="1）何为线性可分"></a><strong>1）何为线性可分</strong></h3><p>在二维空间上，两类点被一条直线完全分开叫做线性可分。</p>
<h3 id="2）何为支持向量"><a href="#2）何为支持向量" class="headerlink" title="2）何为支持向量"></a><strong>2）何为支持向量</strong></h3><p><img src="https://gitee.com/SysYolo/cloudimage/raw/master/img/ubuntu/20220317173057.png"></p>
<p>SVM最优化问题，就是找到各类样本到点到超平面的距离最远，即：找到最大间隔超平面</p>
<h3 id="3）软间隔"><a href="#3）软间隔" class="headerlink" title="3）软间隔"></a><strong>3）软间隔</strong></h3><p>问题：</p>
<ul>
<li>实际应用中，<strong>完全线性可分的样本是很少的</strong>，很多时候是不能够完全线性可分的样本；</li>
</ul>
<p>于是我们就引入了软间隔，<strong>我们允许个别样本点出现在间隔带里</strong></p>
<p><img src="https://gitee.com/SysYolo/cloudimage/raw/master/img/ubuntu/20220317173505.png"></p>
<h3 id="4）核函数"><a href="#4）核函数" class="headerlink" title="4）核函数"></a><strong>4）核函数</strong></h3><p>先前考虑的都是样本的完全线性可分或者大部分样本点的线性可分</p>
<p>但如果样本点是<strong>线性不可分的</strong></p>
<p>就需要将不可分样本映射到高维空间，让样本点在高维空间线性可分；</p>
<p><strong>总结:</strong></p>
<p>对于在有限维度向量空间中线性不可分的样本，我们将其映射到更高维度的向量空间里，再通过间隔最大化的方式，学习得到<strong>支持向量机，就是非线性 SVM。</strong></p>
<h3 id="5）优缺点"><a href="#5）优缺点" class="headerlink" title="5）优缺点"></a><strong>5）优缺点</strong></h3><ul>
<li>有严格的数学理论支持，可解释性强，不依靠统计方法，从而简化了通常的分类和回归问题；</li>
<li>能找出对任务至关重要的关键样本（即：支持向量）；</li>
<li>采用核技巧之后，可以处理<strong>非线性分类&#x2F;回归</strong>任务；</li>
<li>最终决策函数只由少数的支持向量所确定，计算的复杂性取决于<strong>支持向量的数目</strong>，而不是样本空间的维数，这在某种意义上避免了“<strong>维数灾难</strong>”。</li>
</ul>
<h3 id="6）参考博客"><a href="#6）参考博客" class="headerlink" title="6）参考博客"></a><strong>6）参考博客</strong></h3><ul>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/77750026">【机器学习】支持向量机 SVM（非常详细）</a></li>
</ul>
<h2 id="12、决策树"><a href="#12、决策树" class="headerlink" title="12、决策树"></a>12、决策树</h2><h3 id="1）解释-4"><a href="#1）解释-4" class="headerlink" title="1）解释"></a><strong>1）解释</strong></h3><p>决策树是一种机器学习的方法，它是一种十分常用的分类方法；</p>
<p>它是一种树形结构：</p>
<ul>
<li>每个内部节点表示一个属性上的判断</li>
<li>每个分支代表判断结果</li>
<li>每个叶节点代表最终的分类结果</li>
</ul>
<p>它通过给定的样本和标签，通过学习这些样本得到一个决策树，通过这个决策树能够对新的数据给出正确的分类；</p>
<p>我们在做决策树的时候，会经历两个阶段：<strong>构造</strong>和<strong>剪枝</strong>。</p>
<h3 id="2）构造"><a href="#2）构造" class="headerlink" title="2）构造"></a><strong>2）构造</strong></h3><p><strong>构造就是生成一棵完整的决策树</strong>。简单来说，<strong>构造的过程就是选择什么属性作为节点的过程</strong></p>
<h3 id="3）剪枝"><a href="#3）剪枝" class="headerlink" title="3）剪枝"></a><strong>3）剪枝</strong></h3><p>剪枝就是给决策树瘦身，这一步想实现的目标就是，不需要太多的判断，同样可以得到不错的结果。之所以这么做，是为了防止“过拟合”（Overfitting）现象的发生。</p>
<p><img src="https://gitee.com/SysYolo/cloudimage/raw/master/img/ubuntu/20220317211621.png"></p>
<p><strong>剪枝方法</strong></p>
<ul>
<li><strong>预剪枝</strong></li>
</ul>
<p>在决策树<strong>构造时</strong>就进行剪枝。</p>
<p>方法是，在构造的过程中对节点进行评估，</p>
<p>​    <code>if</code>  对某个节点进行划分，</p>
<p>​        在<strong>验证集中不能带来准确性的提升</strong>，那么对这个节点进行划分就没有意义，</p>
<p>这时就会把当前节点作<strong>为叶节点</strong>，不对其进行划分。</p>
<ul>
<li><strong>后剪枝</strong></li>
</ul>
<p>在生成决策树之后再进行剪枝。</p>
<p>通常会从决策树的叶节点开始，逐层向上对每个节点进行评估。</p>
<p>如果剪掉这个节点子树，与保留该节点子树在<strong>分类准确性上差别不大</strong>，或者剪掉该节点子树，能在验证集中带来<strong>准确性的提升</strong>，那么就可以把该节点子树进行剪枝。</p>
<p>方法是：用这个节点子树的<strong>叶子节点</strong>来替代该节点，类标记为这个节点子树中最频繁的那个类。</p>
<h3 id="4）参考"><a href="#4）参考" class="headerlink" title="4）参考"></a><strong>4）参考</strong></h3><ul>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/30059442">决策树(Decision Tree)：通俗易懂之介绍</a></li>
<li><a target="_blank" rel="noopener" href="https://www.cnblogs.com/molieren/articles/10664954.html">决策树</a></li>
</ul>
<h2 id="13、聚类"><a href="#13、聚类" class="headerlink" title="13、聚类"></a>13、聚类</h2><h3 id="1）解释-5"><a href="#1）解释-5" class="headerlink" title="1）解释"></a><strong>1）解释</strong></h3><p>按照某个特定标准(如距离准则)把一个<a target="_blank" rel="noopener" href="https://so.csdn.net/so/search?q=%E6%95%B0%E6%8D%AE%E9%9B%86&spm=1001.2101.3001.7020">数据集</a>分割成不同的类或簇，</p>
<p>使得同一个簇内的数据对象的相似性尽可能大，</p>
<p>同时不在同一个簇中的数据对象的差异性也尽可能地大。</p>
<p><strong>目标</strong></p>
<p>即聚类后同一类的数据尽可能聚集到一起，不同数据尽量分离。</p>
<h3 id="2）聚类和分类的区别"><a href="#2）聚类和分类的区别" class="headerlink" title="2）聚类和分类的区别"></a><strong>2）聚类和分类的区别</strong></h3><p>聚类是<strong>无监督学习</strong>，它没有 lables ；</p>
<ul>
<li><strong>Clustering (聚类)</strong></li>
</ul>
<p>简单地说就是把相似的东西分到一组，聚类的时候，我们并不关心某一类是什么，我们需要实现的目标只是把相似的东西聚到一起。</p>
<p>一个<a target="_blank" rel="noopener" href="https://so.csdn.net/so/search?q=%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95&spm=1001.2101.3001.7020">聚类算法</a>通常只需要知道如何计算相似度就可以开始工作了，因此 clustering 通常并不需要使用训练数据进行学习，这在Machine Learning中被称作unsupervised learning (无监督学习)。 </p>
<ul>
<li><strong>Classification (分类)</strong></li>
</ul>
<p>对于一个classifier，通常需要你告诉它“这个东西被分为某某类”这样一些例子，理想情况下，一个 classifier 会从它得到的训练集中进行“学习”，从而具备对未知数据进行分类的能力，这种提供训练数据的过程通常叫做supervised learning (监督学习)。</p>
<h3 id="3）算法分类"><a href="#3）算法分类" class="headerlink" title="3）算法分类"></a><strong>3）算法分类</strong></h3><ul>
<li><strong>基于划分</strong></li>
</ul>
<p>思想：</p>
<p>有一堆散点需要聚类，我们想要达到的效果：类内的点都足够近，类间的点都足够远</p>
<p>首先，确定这堆散点聚成几类；</p>
<p>然后，挑选几个点作为初试中心点；</p>
<p>再然后，给数据点做迭代重置；</p>
<p><strong>主要算法：</strong></p>
<p><strong>k-means、</strong>k-medoids、k-modes、k-medians、kernel k-means等算法。</p>
<ul>
<li><strong>基于层次</strong></li>
</ul>
<p><strong>合并的层次聚类</strong>   和  <strong>分裂的层次聚类</strong>；</p>
<p>前者是一种自底向上的层次聚类算法，从最底层开始，每一次通过<strong>合并最相似的聚类</strong>，来形成上一层次中的聚类；当全部数据点都合并到一个聚类的时候停止或者达到某个终止条件而结束；</p>
<p>后者是采用自底向下的方法，从一个包含全部数据点的聚类开始，然后分裂为子聚类，递归的继续往下分裂；直到出现只包含一个数据点的单节点聚类出现，即每个聚类中仅包含一个数据点。</p>
<p><strong>主要算法</strong></p>
<p>BIRCH算法、CURE算法、CHAMELEON算法</p>
<ul>
<li><strong>基于密度</strong></li>
</ul>
<p>K-means解决不了的不规则形状的聚类，于是就有了基于密度的方法。</p>
<p>该方法同时对噪声数据的处理比较好，原理：</p>
<p>定义一个圆，设置好最大半价，以及一个圆圈最少容纳几个点</p>
<h2 id="14、降维与度量学习"><a href="#14、降维与度量学习" class="headerlink" title="14、降维与度量学习"></a>14、降维与度量学习</h2><p>参考-</p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/u011826404/article/details/72123031">周志华《Machine Learning》学习笔记（12）–降维与度量学习</a></p>
<h3 id="1）维数灾难、低维嵌入"><a href="#1）维数灾难、低维嵌入" class="headerlink" title="1）维数灾难、低维嵌入"></a><strong>1）维数灾难、低维嵌入</strong></h3><p><strong>维数灾难</strong>：</p>
<p>样本的特征数称为<strong>维数</strong>，高维空间时，数据样本将变得十分稀疏，而此时满足密采样样本的数目将会是一个天文数字，计算距离变得十分复杂；</p>
<p>事实上，在高维情形下出现的数据样本稀疏、距离计算困难等问题，是所有机器学习方法共同面临的严重障碍，被称为”维数灾难”；</p>
<p><strong>解决维数灾难</strong></p>
<p>降维，也称“维数约简”；</p>
<p>通过某种数学变换将原始高维空间 转换为 一个“低维子空间”，这个子空间内，样本密度大幅提高，距离计算也变得更为容易；</p>
<p><strong>为什么能降维</strong></p>
<p>很多时候，人们观测或收集到的数据样本虽然是高维的，但学习任务密切相关的也许仅是某个低维分布，即高维空间中的一个<strong>低维嵌入</strong>。</p>
<p>对高位数据降维还能在一定程度上达到提炼低维优质属性或降噪的效果。</p>
<h3 id="2）主成分分析（PCA）"><a href="#2）主成分分析（PCA）" class="headerlink" title="2）主成分分析（PCA）"></a><strong>2）主成分分析（PCA）</strong></h3><p>最常用的的<strong>降维方法</strong>；</p>
<p>PCA：<strong>通过一个线性变换，将原始空间中的样本投影到新的低维空间中。</strong></p>
<p>简单来说，采用一组<strong>新的基来表示</strong>样本点，其中每一个基向量都是<strong>原来基向量的线性组合</strong>，通过使用尽可能少的新基向量<strong>来表出样本</strong>，从而达到降维的目的</p>
<p>不妨先考虑这样一个问题:对于正交属性空间中</p>
<p>如何用一个超平面(直线的高维推广)对所有样本进行恰当的表达?</p>
<p>容易想到，若存在这样的超平面，那么它大概应具有这样的性质:</p>
<ul>
<li><strong>最近重构性</strong>：样本点到这个超平面的距离都足够近;</li>
<li><strong>最大可分性：</strong>样本点在这个超平面上的投影能尽可能分开.</li>
</ul>
<h3 id="3）核化线性降维"><a href="#3）核化线性降维" class="headerlink" title="3）核化线性降维"></a><strong>3）核化线性降维</strong></h3><p>SVM在处理非线性可分时，通过引入核函数将样本投影到高维特征空间，接着在高维空间再对样本点使用超平面划分，</p>
<p>核函数：先将样本映射到高维空间，再在高维空间中使用线性降维的方法。</p>
<p><strong>核化主成分分析（KPCA）</strong>:<strong>即空间中的任一向量，都可以由该空间中的所有样本线性表示</strong></p>
<p><img src="https://gitee.com/SysYolo/cloudimage/raw/master/img/ubuntu/20220318211310.png"></p>
<h3 id="4）流形学习"><a href="#4）流形学习" class="headerlink" title="4）流形学习"></a><strong>4）流形学习</strong></h3><p><strong>流形学习（manifold learning）是一种借助拓扑流形概念的降维方法，流形是指在局部与欧式空间具有相同的性质</strong>，能用欧氏距离计算样本之间的距离。</p>
<p><strong>这样即使高维空间的分布十分复杂，但是在局部上依然满足欧式空间的性质</strong>，基于流形学习的降维正是这种“<strong>邻域保持</strong>”的思想。</p>
<ul>
<li><strong>等度量映射（Isomap）试图在降维前后保持邻域内样本之间的距离，</strong></li>
</ul>
<p>高维空间中的直线距离是具有误导性的，有时候高维空间的直线距离在低维空间中是不可达到。因此<strong>利用流行在局部上与欧式空间同胚的性质，可以使用近邻距离来逼近样本距离</strong>；</p>
<ul>
<li><strong>而局部线性嵌入（LLE）则是保持邻域内样本之间的线性关系</strong></li>
</ul>
<h3 id="5）度量学习"><a href="#5）度量学习" class="headerlink" title="5）度量学习"></a><strong>5）度量学习</strong></h3><p>我们通常解决维数灾难，即在高维空间进行机器学习任务遇到样本稀疏、距离难计算等诸多的问题；</p>
<p>因此前面讨论的降维方法都试图将原空间投影到一个合适的低维空间中，接着在低维空间进行学习任务从而产生较好的性能。</p>
<p>事实上，<strong>不管高维空间还是低维空间都潜在对应着一个距离度量</strong>，那可不可以直接学习出一个距离度量来等效降维呢？例如：咋们就按照降维后的方式来进行距离的计算，这便是度量学习的初衷。</p>
<h3 id="6）总结"><a href="#6）总结" class="headerlink" title="6）总结"></a><strong>6）总结</strong></h3><p><strong>降维是将原高维空间嵌入到一个合适的低维子空间中，接着在低维空间中进行学习任务；度量学习则是试图去学习出一个距离度量来等效降维的效果</strong>，两者都是为了解决维数灾难带来的诸多问题。</p>
<p><img src="https://gitee.com/SysYolo/cloudimage/raw/master/img/ubuntu/20220318212846.png"></p>
<h2 id="15、集成学习"><a href="#15、集成学习" class="headerlink" title="15、集成学习"></a>15、集成学习</h2><h3 id="1）基本概念"><a href="#1）基本概念" class="headerlink" title="1）基本概念"></a><strong>1）基本概念</strong></h3><h3 id="2）Boosting"><a href="#2）Boosting" class="headerlink" title="2）Boosting"></a><strong>2）Boosting</strong></h3><h3 id="3）随机森林"><a href="#3）随机森林" class="headerlink" title="3）随机森林"></a><strong>3）随机森林</strong></h3></div><div class="article-licensing box"><div class="licensing-title"><p>AI专业问题</p><p><a href="https://www.ferrystars.xyz/2022/03/15/AI专业/">https://www.ferrystars.xyz/2022/03/15/AI专业/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>作者</h6><a href="https://www.ferrystars.xyz"><p>Tlo_oh</p></a></div></div><div class="level-item is-narrow"><div><h6>发布于</h6><p>2022-03-15</p></div></div><div class="level-item is-narrow"><div><h6>更新于</h6><p>2022-03-18</p></div></div><div class="level-item is-narrow"><div><h6>许可协议</h6><p><a class="icon" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a><a class="icon" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a><a class="icon" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><div class="recommend-area"></div><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/social-share.js/1.0.16/css/share.min.css"><div class="social-share"></div><script src="https://cdnjs.loli.net/ajax/libs/social-share.js/1.0.16/js/social-share.min.js"></script></article></div><div class="card"><div class="card-content"><h3 class="menu-label has-text-centered">喜欢这篇文章？打赏一下作者吧</h3><div class="buttons is-centered"><a class="button donate" data-type="alipay"><span class="icon is-small"><i class="fab fa-alipay"></i></span><span>支付宝</span><span class="qrcode"><img src="https://raw.githubusercontent.com/removeif/blog_image/master/img/2019/20190802135456.png" alt="支付宝"></span></a><a class="button donate" data-type="wechat"><span class="icon is-small"><i class="fab fa-weixin"></i></span><span>微信</span><span class="qrcode"><img src="https://raw.githubusercontent.com/removeif/blog_image/master/img/2019/20190802135550.png" alt="微信"></span></a></div></div></div><nav class="post-navigation mt-4 level is-mobile"><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2022/03/13/%E5%A4%8D%E5%BC%8F%E5%8F%82%E8%80%83%E4%B9%A6%E7%AD%BE/"><span class="level-item">复式参考书签</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><!--!--><div class="card"><div class="card-content"><div class="title is-5">评论</div><div class="content" id="comment-container"></div><script>var valine = new Valine({
            el: '#comment-container' ,
            notify: false,
            verify: false,
            appId: '60P1Vz5jjKRwSD6k66ARswSd-MdYXbMMI',
            appKey: 'bYS8KxsiT60tT1FA7YuO0jJh',
            placeholder: '留下您的高见！',
            avatar: 'mp',
            avatarForce: false,
            meta: ["nick","mail","link"],
            pageSize: 10,
            visitor: false,
            highlight: true,
            recordIP: false,
            path:'/2022/03/15/AI专业/',
            lang:'zh-CN',
            enableQQ:true,
            requiredFields:["nick","mail","link"]
        });</script></div></div></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1 is-sticky"><div class="card widget" id="toc" data-type="toc"><div class="card-content"><div class="menu"><h3 class="menu-label">目录</h3><ul class="menu-list"><li><a class="is-flex is-mobile" href="#1、损失函数"><span>1、损失函数</span></a><ul class="menu-list"><li><a class="is-flex is-mobile" href="#1）定义"><span>1）定义</span></a></li><li><a class="is-flex is-mobile" href="#2）应用地方"><span>2）应用地方</span></a></li></ul></li><li><a class="is-flex is-mobile" href="#2、梯度下降"><span>2、梯度下降</span></a><ul class="menu-list"><li><a class="is-flex is-mobile" href="#1）定义-1"><span>1）定义</span></a></li><li><a class="is-flex is-mobile" href="#2）算法中遇到的问题"><span>2）算法中遇到的问题</span></a><ul class="menu-list"><li><a class="is-flex is-mobile" href="#鞍点"><span>鞍点</span></a></li><li><a class="is-flex is-mobile" href="#局部极小值"><span>局部极小值</span></a></li></ul></li></ul></li><li><a class="is-flex is-mobile" href="#3、前、反向传播算法"><span>3、前、反向传播算法</span></a><ul class="menu-list"><li><a class="is-flex is-mobile" href="#1-反向传播算法（BP算法）"><span>1)反向传播算法（BP算法）</span></a><ul class="menu-list"><li><a class="is-flex is-mobile" href="#用途："><span>用途：</span></a></li><li><a class="is-flex is-mobile" href="#定义："><span>定义：</span></a></li><li><a class="is-flex is-mobile" href="#计算方法："><span>计算方法：</span></a></li></ul></li><li><a class="is-flex is-mobile" href="#2-前向传播算法"><span>2)前向传播算法</span></a></li></ul></li><li><a class="is-flex is-mobile" href="#4、正则化"><span>4、正则化</span></a><ul class="menu-list"><li><a class="is-flex is-mobile" href="#1）解释"><span>1）解释</span></a></li><li><a class="is-flex is-mobile" href="#2）常见正则化的策略"><span>2）常见正则化的策略</span></a></li></ul></li><li><a class="is-flex is-mobile" href="#5、卷积神经网络"><span>5、卷积神经网络</span></a><ul class="menu-list"><li><a class="is-flex is-mobile" href="#1）解释-1"><span>1）解释</span></a></li><li><a class="is-flex is-mobile" href="#2）卷积层"><span>2）卷积层</span></a></li><li><a class="is-flex is-mobile" href="#3）池化层"><span>3）池化层</span></a></li><li><a class="is-flex is-mobile" href="#4）全连接层"><span>4）全连接层</span></a></li><li><a class="is-flex is-mobile" href="#5）常见的架构模型"><span>5）常见的架构模型</span></a><ul class="menu-list"><li><a class="is-flex is-mobile" href="#LeNet-5"><span>LeNet-5</span></a></li><li><a class="is-flex is-mobile" href="#AlexNet"><span>AlexNet</span></a></li><li><a class="is-flex is-mobile" href="#VGG"><span>VGG</span></a></li></ul></li></ul></li><li><a class="is-flex is-mobile" href="#6、图像增强"><span>6、图像增强</span></a><ul class="menu-list"><li><a class="is-flex is-mobile" href="#1）作用"><span>1）作用</span></a></li><li><a class="is-flex is-mobile" href="#2）常用方法"><span>2）常用方法</span></a></li></ul></li><li><a class="is-flex is-mobile" href="#7、微调"><span>7、微调</span></a><ul class="menu-list"><li><a class="is-flex is-mobile" href="#1）解释-2"><span>1）解释</span></a></li></ul></li><li><a class="is-flex is-mobile" href="#8、目标检测"><span>8、目标检测</span></a><ul class="menu-list"><li><a class="is-flex is-mobile" href="#1）常用的评价指标"><span>1）常用的评价指标</span></a></li><li><a class="is-flex is-mobile" href="#2）NMS（非极大值抑制）"><span>2）NMS（非极大值抑制）</span></a></li><li><a class="is-flex is-mobile" href="#3）目标检测方法分类"><span>3）目标检测方法分类</span></a></li></ul></li><li><a class="is-flex is-mobile" href="#9、R-CNN"><span>9、R-CNN</span></a><ul class="menu-list"><li><a class="is-flex is-mobile" href="#1）解释-3"><span>1）解释</span></a></li><li><a class="is-flex is-mobile" href="#2）算法总结"><span>2）算法总结</span></a></li><li><a class="is-flex is-mobile" href="#3）Fast-R-CNN"><span>3）Fast R-CNN</span></a></li><li><a class="is-flex is-mobile" href="#4）Faster-R-CNN"><span>4）Faster R-CNN</span></a></li></ul></li><li><a class="is-flex is-mobile" href="#10、yolo系列"><span>10、yolo系列</span></a><ul class="menu-list"><li><a class="is-flex is-mobile" href="#batch-normalization"><span>batch normalization</span></a></li></ul></li><li><a class="is-flex is-mobile" href="#11、支持向量机"><span>11、支持向量机</span></a><ul class="menu-list"><li><a class="is-flex is-mobile" href="#1）何为线性可分"><span>1）何为线性可分</span></a></li><li><a class="is-flex is-mobile" href="#2）何为支持向量"><span>2）何为支持向量</span></a></li><li><a class="is-flex is-mobile" href="#3）软间隔"><span>3）软间隔</span></a></li><li><a class="is-flex is-mobile" href="#4）核函数"><span>4）核函数</span></a></li><li><a class="is-flex is-mobile" href="#5）优缺点"><span>5）优缺点</span></a></li><li><a class="is-flex is-mobile" href="#6）参考博客"><span>6）参考博客</span></a></li></ul></li><li><a class="is-flex is-mobile" href="#12、决策树"><span>12、决策树</span></a><ul class="menu-list"><li><a class="is-flex is-mobile" href="#1）解释-4"><span>1）解释</span></a></li><li><a class="is-flex is-mobile" href="#2）构造"><span>2）构造</span></a></li><li><a class="is-flex is-mobile" href="#3）剪枝"><span>3）剪枝</span></a></li><li><a class="is-flex is-mobile" href="#4）参考"><span>4）参考</span></a></li></ul></li><li><a class="is-flex is-mobile" href="#13、聚类"><span>13、聚类</span></a><ul class="menu-list"><li><a class="is-flex is-mobile" href="#1）解释-5"><span>1）解释</span></a></li><li><a class="is-flex is-mobile" href="#2）聚类和分类的区别"><span>2）聚类和分类的区别</span></a></li><li><a class="is-flex is-mobile" href="#3）算法分类"><span>3）算法分类</span></a></li></ul></li><li><a class="is-flex is-mobile" href="#14、降维与度量学习"><span>14、降维与度量学习</span></a><ul class="menu-list"><li><a class="is-flex is-mobile" href="#1）维数灾难、低维嵌入"><span>1）维数灾难、低维嵌入</span></a></li><li><a class="is-flex is-mobile" href="#2）主成分分析（PCA）"><span>2）主成分分析（PCA）</span></a></li><li><a class="is-flex is-mobile" href="#3）核化线性降维"><span>3）核化线性降维</span></a></li><li><a class="is-flex is-mobile" href="#4）流形学习"><span>4）流形学习</span></a></li><li><a class="is-flex is-mobile" href="#5）度量学习"><span>5）度量学习</span></a></li><li><a class="is-flex is-mobile" href="#6）总结"><span>6）总结</span></a></li></ul></li><li><a class="is-flex is-mobile" href="#15、集成学习"><span>15、集成学习</span></a><ul class="menu-list"><li><a class="is-flex is-mobile" href="#1）基本概念"><span>1）基本概念</span></a></li><li><a class="is-flex is-mobile" href="#2）Boosting"><span>2）Boosting</span></a></li><li><a class="is-flex is-mobile" href="#3）随机森林"><span>3）随机森林</span></a></li></ul></li></ul></div></div><style>.menu-list > li > a.is-active + .menu-list { display: block; }.menu-list > li > a + .menu-list { display: none; }</style><script src="/js/toc.js" defer></script></div><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="https://gitee.com/SysYolo/cloudimage/raw/master/img/ubuntu/mypicture.jpg" alt="Tlo_oh"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Tlo_oh</p><p class="is-size-6 is-block">以有涯随无涯！</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>中国</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">文章</p><a href="/archives"><p class="title">12</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">分类</p><a href="/categories"><p class="title">8</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">标签</p><a href="/tags"><p class="title">10</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/ppoffice" target="_blank" rel="noopener">关注我</a></div><div class="level is-mobile"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/removeif"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Weibo" href="https://weibo.com/removeif"><i class="fab fa-weibo"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Email" href="/tloooh888@gmail.com"><i class="fa fa-envelope"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Next" href="https://removeif.github.io/remove.io"><i class="fab fa-dribbble"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/atom.xml"><i class="fas fa-rss"></i></a></div><div><hr><p id="hitokoto">:D 一言句子获取中...</p><script type="text/javascript" defer>function getYiyan(){
                                $.getJSON("https://v1.hitokoto.cn/", function (data) {
                                if(data){
                                    $('#hitokoto').html("");
                                    $('#hitokoto').append("<strong style='color: #3273dc;'>"+data.hitokoto+"</strong>"+
                                    "<p>"+"来源《"+data.from+"》</p><p>提供者-"+data.creator+"</p>");
                                }});}
                                $(function (){getYiyan();$('#hitokoto').click(function(){getYiyan();})});</script></div></div></div><div class="card widget"><div class="card-content"><h3 class="menu-label">最新文章</h3><article class="media"><figure class="media-left"><a class="image" href="/2022/03/15/AI%E4%B8%93%E4%B8%9A/"><img src="https://gitee.com/SysYolo/cloudimage/raw/master/img/ubuntu/20220321132955.png" alt="AI专业问题"></a></figure><div class="media-content"><p class="date"><time dateTime="2022-03-15T03:30:06.000Z">2022-03-15</time></p><p class="title"><a href="/2022/03/15/AI%E4%B8%93%E4%B8%9A/">AI专业问题</a></p><p class="categories"><a href="/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/">人工智能</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/2022/03/13/%E5%A4%8D%E5%BC%8F%E5%8F%82%E8%80%83%E4%B9%A6%E7%AD%BE/"><img src="https://gitee.com/SysYolo/cloudimage/raw/master/img/ubuntu/20220313094143.jpeg" alt="复式参考书签"></a></figure><div class="media-content"><p class="date"><time dateTime="2022-03-13T01:32:43.000Z">2022-03-13</time></p><p class="title"><a href="/2022/03/13/%E5%A4%8D%E5%BC%8F%E5%8F%82%E8%80%83%E4%B9%A6%E7%AD%BE/">复式参考书签</a></p><p class="categories"><a href="/categories/%E7%A0%94%E7%A9%B6%E7%94%9F/">研究生</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/2022/03/11/clash-Tun%E6%A8%A1%E5%BC%8F/"><img src="https://gitee.com/SysYolo/cloudimage/raw/master/img/ubuntu/20220313084350.png" alt="clash Tun模式实现设备共享上网"></a></figure><div class="media-content"><p class="date"><time dateTime="2022-03-11T15:40:06.000Z">2022-03-11</time></p><p class="title"><a href="/2022/03/11/clash-Tun%E6%A8%A1%E5%BC%8F/">clash Tun模式实现设备共享上网</a></p><p class="categories"><a href="/categories/Linux/">Linux</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/2022/03/08/leetcode-record/"><img src="https://gimg2.baidu.com/image_search/src=http%3A%2F%2Fpic3.zhimg.com%2Fv2-47ddc1485d3220d1af40df818b7a855e_180x120.jpg&amp;refer=http%3A%2F%2Fpic3.zhimg.com&amp;app=2002&amp;size=f9999,10000&amp;q=a80&amp;n=0&amp;g=0n&amp;fmt=jpeg?sec=1649343841&amp;t=34cac5a54e61996bf623087d53fcc0c2" alt="leetcode-剑指offer"></a></figure><div class="media-content"><p class="date"><time dateTime="2022-03-08T14:59:20.000Z">2022-03-08</time></p><p class="title"><a href="/2022/03/08/leetcode-record/">leetcode-剑指offer</a></p><p class="categories"><a href="/categories/leetcode/">leetcode</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/2022/03/07/Science%20Internet/"><img src="https://gitee.com/SysYolo/cloudimage/raw/master/img/ubuntu/20220306164206.png" alt="ubuntu 安装Clash 科学上网"></a></figure><div class="media-content"><p class="date"><time dateTime="2022-03-07T05:47:21.000Z">2022-03-07</time></p><p class="title"><a href="/2022/03/07/Science%20Internet/">ubuntu 安装Clash 科学上网</a></p><p class="categories"><a href="/categories/%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91/">科学上网</a></p></div></article></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">分类</h3><ul class="menu-list"><li><a class="level is-mobile is-marginless" href="/categories/Deep-Learning/"><span class="level-start"><span class="level-item">Deep Learning</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/Linux/"><span class="level-start"><span class="level-item">Linux</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/leetcode/"><span class="level-start"><span class="level-item">leetcode</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"><span class="level-start"><span class="level-item">人工智能</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/"><span class="level-start"><span class="level-item">博客搭建</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"><span class="level-start"><span class="level-item">数字图像处理</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/%E7%A0%94%E7%A9%B6%E7%94%9F/"><span class="level-start"><span class="level-item">研究生</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91/"><span class="level-start"><span class="level-item">科学上网</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></div></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">归档</h3><ul class="menu-list"><li><a class="level is-mobile is-marginless" href="/archives/2022/03/"><span class="level-start"><span class="level-item">三月 2022</span></span><span class="level-end"><span class="level-item tag">12</span></span></a></li></ul></div></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">标签</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/%E6%9D%82%E9%A1%B9/"><span class="tag">杂项</span><span class="tag is-grey-lightest">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ubuntu/"><span class="tag">ubuntu</span><span class="tag is-grey-lightest">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/blog/"><span class="tag">blog</span><span class="tag is-grey-lightest">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Deep-Learning/"><span class="tag">Deep Learning</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Machine-Learning/"><span class="tag">Machine Learning</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/python/"><span class="tag">python</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%88%B7%E9%A2%98/"><span class="tag">刷题</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%A4%8D%E8%AF%95/"><span class="tag">复试</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%A4%8D%E8%AF%95%E5%8F%82%E8%80%83/"><span class="tag">复试参考</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0/"><span class="tag">统计学习</span><span class="tag is-grey-lightest">1</span></a></div></div></div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">订阅更新</h3><form action="https://feedburner.google.com/fb/a/mailverify" method="post" target="popupwindow" onsubmit="window.open(&#039;https://feedburner.google.com/fb/a/mailverify?uri=&#039;,&#039;popupwindow&#039;,&#039;scrollbars=yes,width=550,height=520&#039;);return true"><input type="hidden" value="" name="uri"><input type="hidden" name="loc" value="en_US"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="订阅"></div></div></form></div></div></div><!--!--><div class="column-right-shadow is-hidden-widescreen"></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.png" alt="Tlo_oh" height="28"></a><p class="size-small"><span>&copy; 2022 Tlo_oh</span>  Powered by <a href="https://hexo.io/" target="_blank">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank">Icarus</a> &amp; <a href="https://github.com/removeif/hexo-theme-amazing" target="_blank">Amazing</a> <br><span>© 版权说明：[本网站所有内容均收集于互联网或自己创作,<br />&nbsp;&nbsp;&nbsp;&nbsp;方便于网友与自己学习交流，如有侵权，请<a href="/message" target="_blank">留言</a>，立即处理]<br /></span><span><span id="statistic-times">loading...</span><script>function createTime(time) {
            var n = new Date(time);
            now.setTime(now.getTime() + 250),
                days = (now - n) / 1e3 / 60 / 60 / 24,
                dnum = Math.floor(days),
                hours = (now - n) / 1e3 / 60 / 60 - 24 * dnum,
                hnum = Math.floor(hours),
            1 == String(hnum).length && (hnum = "0" + hnum),
                minutes = (now - n) / 1e3 / 60 - 1440 * dnum - 60 * hnum,
                mnum = Math.floor(minutes),
            1 == String(mnum).length && (mnum = "0" + mnum),
                seconds = (now - n) / 1e3 - 86400 * dnum - 3600 * hnum - 60 * mnum,
                snum = Math.round(seconds),
            1 == String(snum).length && (snum = "0" + snum),
                document.getElementById("statistic-times").innerHTML = "❤️本站自 <strong>"+time.split(" ")[0].replace(/\//g,".")+"</strong> 已运行 <strong>" + dnum + "</strong> 天 <strong>" + hnum + "</strong> 小时 <strong>" + mnum + "</strong> 分 <strong>" + snum + "</strong> 秒！❤️";
        }var now = new Date();setInterval("createTime('2022/03/03 00:00:00')", 250,"");</script><br></span><div class="size-small"><span>❤️感谢 <strong><span id="busuanzi_value_site_uv">99+</span></strong> 小伙伴的 <strong><span id="busuanzi_value_site_pv">99+</span></strong> 次光临！❤️</span></div></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/removeif/hexo-theme-amazing"><i class="fab fa-github"></i></a></p></div><div class="sideMusic"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css"><script src="/js/APlayer.min.js"></script><script src="https://cdn.jsdelivr.net/npm/meting@2/dist/Meting.min.js"></script><meting-js style="width: auto;height: 2000px;" server="netease" type="playlist" id="2364053447" theme="#2980b9" loop="all" autoplay="false" order="list" storageName="aplayer-setting" lrctype="0" list-max-height="400px" fixed="true"></meting-js></div></div></div></div></footer><script src="https://cdnjs.loli.net/ajax/libs/moment.js/2.22.2/moment-with-locales.min.js"></script><script src="https://cdnjs.loli.net/ajax/libs/clipboard.js/2.0.4/clipboard.min.js" async></script><script>moment.locale("zh-CN");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdnjs.loli.net/ajax/libs/lightgallery/1.6.8/js/lightgallery.min.js" defer></script><script src="https://cdnjs.loli.net/ajax/libs/justifiedGallery/3.7.0/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><script>$.getScript('/js/comment-issue-data.js',function(){loadIssueData('60P1Vz5jjKRwSD6k66ARswSd-MdYXbMMI','bYS8KxsiT60tT1FA7YuO0jJh','Tlo_oh','undefined',true);})</script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script><script src="https://cdn.jsdelivr.net/npm/pjax@0.2.8/pjax.js"></script><script type="text/javascript">var pjax = new Pjax({
            elements: "a",//代表点击链接就更新
            selectors: [  //代表要更新的节点
                ".section",
                "title"
            ],
            cache: true,
            cacheBust:false
        })

        function loadBusuanzi(){
        $.getScript("//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js", function () {});
        }

        // 开始 PJAX 执行的函数
        document.addEventListener('pjax:send', function () {
        });
        
        // PJAX 完成之后执行的函数，可以和上面的重载放在一起
        document.addEventListener('pjax:complete', function () {
            $(".section").css({opacity:1});
            if(true){
                $.getScript('/js/comment-issue-data.js',function(){loadIssueData('60P1Vz5jjKRwSD6k66ARswSd-MdYXbMMI','bYS8KxsiT60tT1FA7YuO0jJh','Tlo_oh','undefined',true);});
            }
            if(false){
                loadMathJax();
            }
            loadMainJs(jQuery, window.moment, window.ClipboardJS, window.IcarusThemeSettings);
            loadBackTop();
            loadBusuanzi();
            if(typeof loadBanner == 'function'){
                loadBanner();
            }
        });</script></body></html>